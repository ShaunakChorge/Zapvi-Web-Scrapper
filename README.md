# 🌐 Web Scraper for E-commerce Products 📦

Welcome to the Web Scraper project! This repository features a Jupyter Notebook that automates the extraction of product information from e-commerce websites. Specifically, this web scraper has been created to target back covers for smartphones available on **zapvi.in**.

## 🎯 Purpose

The purpose of this project is to provide a streamlined solution for collecting product data from online retailers. This tool is ideal for researchers, marketers, and anyone interested in analyzing product offerings and prices in the e-commerce space, particularly for products listed on zapvi.in.

## ✨ Features

- **Automated Data Collection:** Effortlessly scrape product names, prices, and URLs from zapvi.in.
- **Customizable Scraping:** Easily modify the base URL and parameters to target different products or categories.
- **Structured Output:** Data is organized into a clean and user-friendly format using Pandas.

## 🛠️ Technologies Used

- **Python 3.x:** The primary programming language for the project.
- **Jupyter Notebook:** For interactive coding and data visualization.
- **Requests:** To send HTTP requests and retrieve web content.
- **BeautifulSoup:** For parsing HTML and extracting data.
- **Pandas:** For data manipulation and analysis.

## 📚 Getting Started

### Prerequisites

To run this project, you'll need:

- Python 3.x
- Jupyter Notebook
- Required libraries:
  - `requests`
  - `BeautifulSoup`
  - `pandas`
## 📚 Getting Started

### Prerequisites

To run this project, you'll need:

- Python 3.x
- Jupyter Notebook
- Required libraries:
  - `requests`
  - `BeautifulSoup`
  - `pandas`


You can install the required libraries using pip:

  ```bash
  pip install requests beautifulsoup4 pandas
  ```

### Usage
  
  Clone this repository:

  ```bash
    git clone https://github.com/yourusername/web-scraper.git
    cd web-scraper
  ```
  Open the Jupyter Notebook:
  
  ```bash
    jupyter notebook webscrapper.ipynb
  ```
  Run the cells to scrape data from the specified website.


## 📝 Data Output
The scraped data will be displayed in a structured format, showcasing product names, prices, and URLs. Optionally, you can save the data to a CSV file for future reference.



## 🤝 Contributing
Contributions are welcome! If you have suggestions for improvements or additional features, feel free to open an issue or submit a pull request.




<div align="right">
  <p>Made with ❤️ by Shaunak Chorge</p>
</div>



